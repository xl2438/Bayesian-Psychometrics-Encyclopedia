% $ biblatex auxiliary file $
% $ biblatex bbl format version 3.2 $
% Do not modify the above lines!
%
% This is an auxiliary file used by the 'biblatex' package.
% This file may safely be deleted. It will be recreated by
% biber as required.
%
\begingroup
\makeatletter
\@ifundefined{ver@biblatex.sty}
  {\@latex@error
     {Missing 'biblatex' package}
     {The bibliography requires the 'biblatex' package.}
      \aftergroup\endinput}
  {}
\endgroup


\refsection{0}
  \datalist[entry]{apa/global//global/global}
    \entry{bock_fitting_1970}{article}{}
      \name{author}{2}{}{%
        {{un=0,uniquepart=base,hash=cc827fb0c4dece00630f1bb3c29e4a51}{%
           family={Bock},
           familyi={B\bibinitperiod},
           given={Darrell\bibnamedelima R.},
           giveni={D\bibinitperiod\bibinitdelim R\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=7fea8bc828ddbc0a1f9887d8edbbf40f}{%
           family={Lieberman},
           familyi={L\bibinitperiod},
           given={Marcus},
           giveni={M\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{52712198a6d85456270fe8d29ecbb25a}
      \strng{fullhash}{52712198a6d85456270fe8d29ecbb25a}
      \strng{bibnamehash}{52712198a6d85456270fe8d29ecbb25a}
      \strng{authorbibnamehash}{52712198a6d85456270fe8d29ecbb25a}
      \strng{authornamehash}{52712198a6d85456270fe8d29ecbb25a}
      \strng{authorfullhash}{52712198a6d85456270fe8d29ecbb25a}
      \field{sortinit}{B}
      \field{sortinithash}{d7095fff47cda75ca2589920aae98399}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{year}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{A method of estimating the parameters of the normal ogive model for diehotomously scored item-responses by maximum likelihood is demon- strated. Although the procedure requires numerical integration in order to evaluate the likelihood equations, a computer implemented Newton-l{\textasciitilde}aphson solution is shown to be straightforward in other respects. Empirical tests of the procedure show that the resulting estimates are very similar to those based on a conventional analysis of item "difficulties" and first factor load- ings obtained from the matrix of tetrachoric correlation coefficients. Problems of testing the fit of the model, and of obtaining invariant parameters are discussed.}
      \field{issn}{00333123}
      \field{journaltitle}{Psychometrika}
      \field{month}{6}
      \field{number}{2}
      \field{title}{Fitting a response model for n dichotomously scored items}
      \field{urlday}{14}
      \field{urlmonth}{3}
      \field{urlyear}{2016}
      \field{volume}{35}
      \field{year}{1970}
      \field{urldateera}{ce}
      \field{pages}{179\bibrangedash 197}
      \range{pages}{19}
      \verb{doi}
      \verb 10.1007/BF02291262
      \endverb
      \verb{urlraw}
      \verb http://link.springer.com/10.1007/BF02291262
      \endverb
      \verb{url}
      \verb http://link.springer.com/10.1007/BF02291262
      \endverb
    \endentry
    \entry{cowles_markov_1996}{article}{}
      \name{author}{2}{}{%
        {{un=0,uniquepart=base,hash=80ab7f3ca3bb0e424e92e1b7fab39210}{%
           family={Cowles},
           familyi={C\bibinitperiod},
           given={Mary\bibnamedelima Kathryn},
           giveni={M\bibinitperiod\bibinitdelim K\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=72c956f4cc80d0b12a34e19fbda3e6f4}{%
           family={Carlin},
           familyi={C\bibinitperiod},
           given={Bradley\bibnamedelima P.},
           giveni={B\bibinitperiod\bibinitdelim P\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{8ba9aa7286f3ebf8434ca042f2c20488}
      \strng{fullhash}{8ba9aa7286f3ebf8434ca042f2c20488}
      \strng{bibnamehash}{8ba9aa7286f3ebf8434ca042f2c20488}
      \strng{authorbibnamehash}{8ba9aa7286f3ebf8434ca042f2c20488}
      \strng{authornamehash}{8ba9aa7286f3ebf8434ca042f2c20488}
      \strng{authorfullhash}{8ba9aa7286f3ebf8434ca042f2c20488}
      \field{sortinit}{C}
      \field{sortinithash}{4d103a86280481745c9c897c925753c0}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{year}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{A critical issue for users of Markov chain Monte Carlo (MCMC) methods in applications is how to determine when it is safe to stop sampling and use the samples to estimate characteristics of the distribution of interest. Research into methods of computing theoretical convergence bounds holds promise for the future but to date has yielded relatively little of practical use in applied work. Consequently, most MCMC users address the convergence problem by applying diagnostic tools to the output produced by running their samplers. After giving a brief overview of the area, we provide an expository review of 13 convergence diagnostics, describing the theoretical basis and practical implementation of each. We then compare their performance in two simple models and conclude that all of the methods can fail to detect the sorts of convergence failure that they were designed to identify. We thus recommend a combination of strategies aimed at evaluating and accelerating MCMC sampler convergence, including applying diagnostic procedures to a small number of parallel chains, monitoring autocorrelations and cross-correlations, and modifying parametrizations or sampling algorithms appropriately. We emphasize, however, that it is not possible to say with certainty that a finite sample from an MCMC algorithm is representative of an underlying stationary distribution.}
      \field{journaltitle}{Journal of the American Statistical Association}
      \field{title}{Markov {Chain} {Monte} {Carlo} {Convergence} {Diagnostics}: {A} {Comparative} {Review}}
      \field{year}{1996}
      \verb{doi}
      \verb 10.1080/01621459.1996.10476956
      \endverb
      \keyw{Autocorrelation,Gibbs sampler,Metropolis-Hastings algorithm}
    \endentry
    \entry{culpepper_bayesian_2015}{article}{}
      \name{author}{1}{}{%
        {{un=0,uniquepart=base,hash=9dc2433225e16635f8cbd0cade56a8a1}{%
           family={Culpepper},
           familyi={C\bibinitperiod},
           given={Steven\bibnamedelima Andrew},
           giveni={S\bibinitperiod\bibinitdelim A\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{9dc2433225e16635f8cbd0cade56a8a1}
      \strng{fullhash}{9dc2433225e16635f8cbd0cade56a8a1}
      \strng{bibnamehash}{9dc2433225e16635f8cbd0cade56a8a1}
      \strng{authorbibnamehash}{9dc2433225e16635f8cbd0cade56a8a1}
      \strng{authornamehash}{9dc2433225e16635f8cbd0cade56a8a1}
      \strng{authorfullhash}{9dc2433225e16635f8cbd0cade56a8a1}
      \field{sortinit}{C}
      \field{sortinithash}{4d103a86280481745c9c897c925753c0}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{year}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{A Bayesian model formulation of the deterministic inputs, noisy ''and'' gate (DINA) model is presented. Gibbs sampling is employed to simulate from the joint posterior distribution of item guessing and slipping parameters, subject attribute parameters, and latent class probabilities. The procedure extends concepts in Be´guin and Glas, Culpepper, and Sahu for estimating the guessing and slipping parameters in the three-and four-parameter normal-ogive models. The ability of the model to recover parameters is demonstrated in a simulation study. The technique is applied to a mental rotation test. The algorithm and vignettes are freely available to researchers as the ''dina'' R package.}
      \field{issn}{1076-9986}
      \field{journaltitle}{Journal of Educational and Behavioral Statistics}
      \field{month}{10}
      \field{number}{5}
      \field{title}{Bayesian {Estimation} of the {DINA} {Model} {With} {Gibbs} {Sampling}}
      \field{urlday}{30}
      \field{urlmonth}{3}
      \field{urlyear}{2017}
      \field{volume}{40}
      \field{year}{2015}
      \field{urldateera}{ce}
      \field{pages}{454\bibrangedash 476}
      \range{pages}{23}
      \verb{doi}
      \verb 10.3102/1076998615595403
      \endverb
      \verb{file}
      \verb PDF:/home/xiang/Zotero/storage/NXEF3FTA/Culpepper - 2015 - Bayesian Estimation of the DINA Model With Gibbs Sampling(2).pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb http://jeb.sagepub.com/cgi/doi/10.3102/1076998615595403
      \endverb
      \verb{url}
      \verb http://jeb.sagepub.com/cgi/doi/10.3102/1076998615595403
      \endverb
      \keyw{bayesian statistics,Bayesian statistics,cognitive diagnosis,markov chain monte carlo,Markov chain Monte Carlo,spatial cognition}
    \endentry
    \entry{decarlo_recognizing_2012}{article}{}
      \name{author}{1}{}{%
        {{un=0,uniquepart=base,hash=d3a0c15c19339e3729a2fe5f84701942}{%
           family={DeCarlo},
           familyi={D\bibinitperiod},
           given={Lawrence\bibnamedelima T.},
           giveni={L\bibinitperiod\bibinitdelim T\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{d3a0c15c19339e3729a2fe5f84701942}
      \strng{fullhash}{d3a0c15c19339e3729a2fe5f84701942}
      \strng{bibnamehash}{d3a0c15c19339e3729a2fe5f84701942}
      \strng{authorbibnamehash}{d3a0c15c19339e3729a2fe5f84701942}
      \strng{authornamehash}{d3a0c15c19339e3729a2fe5f84701942}
      \strng{authorfullhash}{d3a0c15c19339e3729a2fe5f84701942}
      \field{sortinit}{D}
      \field{sortinithash}{6f385f66841fb5e82009dc833c761848}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{year}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{In the typical application of a cognitive diagnosis model, the Q-matrix, which reflects the theory with respect to the skills indicated by the items, is assumed to be known. However, the Q-matrix is usually determined by expert judgment, and so there can be uncertainty about some of its elements. Here it is shown that this uncertainty can be recognized and explored via a Bayesian extension of the DINA (deterministic input noisy and) model. The approach used is to specify some elements of the Q-matrix as being random rather than as fixed; posterior distributions can then be used to obtain information about elements whose inclusion in the Q-matrix is questionable. Simulations show that this approach helps to recover the true Q-matrix when there is uncertainty about some elements. An application to the fraction-subtraction data of K. K. Tatsuoka suggests a modified Q-matrix that gives improved relative fit. © The Author(s) 2012.}
      \field{issn}{0146-6216}
      \field{journaltitle}{Applied Psychological Measurement}
      \field{month}{9}
      \field{number}{6}
      \field{title}{Recognizing {Uncertainty} in the {Q}-{Matrix} via a {Bayesian} {Extension} of the {DINA} {Model}}
      \field{urlday}{25}
      \field{urlmonth}{3}
      \field{urlyear}{2016}
      \field{volume}{36}
      \field{year}{2012}
      \field{urldateera}{ce}
      \field{pages}{447\bibrangedash 468}
      \range{pages}{22}
      \verb{doi}
      \verb 10.1177/0146621612449069
      \endverb
      \verb{urlraw}
      \verb http://journals.sagepub.com/doi/10.1177/0146621612449069
      \endverb
      \verb{url}
      \verb http://journals.sagepub.com/doi/10.1177/0146621612449069
      \endverb
    \endentry
    \entry{fox_bayesian_2001}{article}{}
      \name{author}{2}{}{%
        {{un=0,uniquepart=base,hash=9b24cbad5ecd078996ef5ce25d629567}{%
           family={Fox},
           familyi={F\bibinitperiod},
           given={Jean\bibnamedelima Paul},
           giveni={J\bibinitperiod\bibinitdelim P\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=7a0aa5d20e31fc265dabcb7e044767e6}{%
           family={Glas},
           familyi={G\bibinitperiod},
           given={Cees\bibnamedelima A.W.},
           giveni={C\bibinitperiod\bibinitdelim A\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{0280edf2f0f827593f390a607f99c459}
      \strng{fullhash}{0280edf2f0f827593f390a607f99c459}
      \strng{bibnamehash}{0280edf2f0f827593f390a607f99c459}
      \strng{authorbibnamehash}{0280edf2f0f827593f390a607f99c459}
      \strng{authornamehash}{0280edf2f0f827593f390a607f99c459}
      \strng{authorfullhash}{0280edf2f0f827593f390a607f99c459}
      \field{sortinit}{F}
      \field{sortinithash}{2638baaa20439f1b5a8f80c6c08a13b4}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{year}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{In this article, a two-level regression model is imposed on the ability parameters in an item response theory (IRT) model. The advantage of using latent rather than observed scores as dependent variables of a multilevel model is that it offers the possibility of separating the influence of item difficulty and ability level and modeling response variation and measurement error. Another advantage is that, contrary to observed scores, latent scores are test-independent, which offers the possibility of using results from different tests in one analysis where the parameters of the IRT model and the multilevel model can be concurrently estimated. The two-parameter normal ogive model is used for the IRT measurement model. It will be shown that the parameters of the two-parameter normal ogive model and the multilevel model can be estimated in a Bayesian framework using Gibbs sampling. Examples using simulated and real data are given.}
      \field{issn}{00333123}
      \field{journaltitle}{Psychometrika}
      \field{number}{2}
      \field{title}{Bayesian estimation of a multilevel {IRT} model using {Gibbs} sampling}
      \field{volume}{66}
      \field{year}{2001}
      \verb{doi}
      \verb 10.1007/BF02294839
      \endverb
    \endentry
    \entry{gelman_stan:_2015}{article}{}
      \name{author}{3}{}{%
        {{un=0,uniquepart=base,hash=ba82e2f52cafc6076f0de4ae6be66db0}{%
           family={Gelman},
           familyi={G\bibinitperiod},
           given={A.},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=98056d9ddecda0076a31a183e3e69326}{%
           family={Lee},
           familyi={L\bibinitperiod},
           given={D.},
           giveni={D\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=28f6068ba57e60c5e27fc2490a8e1ffd}{%
           family={Guo},
           familyi={G\bibinitperiod},
           given={J.},
           giveni={J\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{a428ac65ac4ae3fdbf2c9d0835d9c6f3}
      \strng{fullhash}{997043f515dd99ac458511025f2a88cd}
      \strng{bibnamehash}{997043f515dd99ac458511025f2a88cd}
      \strng{authorbibnamehash}{997043f515dd99ac458511025f2a88cd}
      \strng{authornamehash}{a428ac65ac4ae3fdbf2c9d0835d9c6f3}
      \strng{authorfullhash}{997043f515dd99ac458511025f2a88cd}
      \field{extraname}{1}
      \field{sortinit}{G}
      \field{sortinithash}{32d67eca0634bf53703493fb1090a2e8}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{year}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Stan is a free and open-source C++ program that performs Bayesian inference or optimiza- tion for arbitrary user-specified models and can be called from the command line, R, Python, Matlab, or Julia, and has great promise for fitting large and complex statistical models in many areas of application. We discuss Stan from users’ and developers’ perspectives and illustrate with a simple but nontrivial nonlinear regression example.}
      \field{journaltitle}{Journal of Educational and Behavioral Statistics}
      \field{number}{5}
      \field{title}{Stan: {A} {Probabilistic} {Programming} {Language} for {Bayesian} {Inference} and {Optimization}}
      \field{volume}{40}
      \field{year}{2015}
      \field{pages}{530\bibrangedash 543}
      \range{pages}{14}
      \keyw{bayesian inference,hierarchical models,probabilistic programming,statisti-}
    \endentry
    \entry{gelman_bayesian_2013}{book}{}
      \name{author}{6}{}{%
        {{un=0,uniquepart=base,hash=1e1eb60e3b6e222217bf8e9b24070b28}{%
           family={Gelman},
           familyi={G\bibinitperiod},
           given={Andrew},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=5f088783ee75f9f0908eeb4fa9571a31}{%
           family={Carlin},
           familyi={C\bibinitperiod},
           given={John\bibnamedelima B},
           giveni={J\bibinitperiod\bibinitdelim B\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=fd9cbf9e3046ffa6a7cecf24e1a46b03}{%
           family={Stern},
           familyi={S\bibinitperiod},
           given={Hal\bibnamedelima S},
           giveni={H\bibinitperiod\bibinitdelim S\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=84545b54e408a7eba6bf9280fd2eaae7}{%
           family={Dunson},
           familyi={D\bibinitperiod},
           given={David\bibnamedelima B},
           giveni={D\bibinitperiod\bibinitdelim B\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=5d36e97683cbc9d6ef06fc2ec40becb0}{%
           family={Vehtari},
           familyi={V\bibinitperiod},
           given={Aki},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=49a367b6280de8a239f8bbdd573f996f}{%
           family={Rubin},
           familyi={R\bibinitperiod},
           given={Donald\bibnamedelima B},
           giveni={D\bibinitperiod\bibinitdelim B\bibinitperiod},
           givenun=0}}%
      }
      \list{publisher}{2}{%
        {Chapman}%
        {Hall/CRC}%
      }
      \strng{namehash}{7b511f44eded88e08c98470ecd75568d}
      \strng{fullhash}{5c09c13430845c0df008aa82cfeb78ef}
      \strng{bibnamehash}{5c09c13430845c0df008aa82cfeb78ef}
      \strng{authorbibnamehash}{5c09c13430845c0df008aa82cfeb78ef}
      \strng{authornamehash}{7b511f44eded88e08c98470ecd75568d}
      \strng{authorfullhash}{5c09c13430845c0df008aa82cfeb78ef}
      \field{extraname}{2}
      \field{sortinit}{G}
      \field{sortinithash}{32d67eca0634bf53703493fb1090a2e8}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{year}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Now in its third edition, this classic book is widely considered the leading text on Bayesian methods, lauded for its accessible, practical approach to analyzing data and solving research problems. Bayesian Data Analysis, Third Edition continues to take an applied approach to analysis using up-to-date Bayesian methods. The authors—all leaders in the statistics community—introduce basic concepts from a data-analytic perspective before presenting advanced methods. Throughout the text, numerous worked examples drawn from real applications and research emphasize the use of Bayesian inference in practice. New to the Third Edition Four new chapters on nonparametric modeling Coverage of weakly informative priors and boundary-avoiding priors Updated discussion of cross-validation and predictive information criteria Improved convergence monitoring and effective sample size calculations for iterative simulation Presentations of Hamiltonian Monte Carlo, variational Bayes, and expectation propagation New and revised software code The book can be used in three different ways. For undergraduate students, it introduces Bayesian inference starting from first principles. For graduate students, the text presents effective current approaches to Bayesian modeling and computation in statistics and related fields. For researchers, it provides an assortment of Bayesian methods in applied statistics. Additional materials, including data sets used in the examples, solutions to selected exercises, and software instructions, are available on the book’s web page.}
      \field{isbn}{978-1-4398-4095-5}
      \field{title}{Bayesian {Data} {Analysis}}
      \field{year}{2013}
    \endentry
    \entry{gelman_inference_1992}{article}{}
      \name{author}{2}{}{%
        {{un=0,uniquepart=base,hash=1e1eb60e3b6e222217bf8e9b24070b28}{%
           family={Gelman},
           familyi={G\bibinitperiod},
           given={Andrew},
           giveni={A\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=49a367b6280de8a239f8bbdd573f996f}{%
           family={Rubin},
           familyi={R\bibinitperiod},
           given={Donald\bibnamedelima B.},
           giveni={D\bibinitperiod\bibinitdelim B\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{ace621ada30e7015366685782e55c297}
      \strng{fullhash}{ace621ada30e7015366685782e55c297}
      \strng{bibnamehash}{ace621ada30e7015366685782e55c297}
      \strng{authorbibnamehash}{ace621ada30e7015366685782e55c297}
      \strng{authornamehash}{ace621ada30e7015366685782e55c297}
      \strng{authorfullhash}{ace621ada30e7015366685782e55c297}
      \field{sortinit}{G}
      \field{sortinithash}{32d67eca0634bf53703493fb1090a2e8}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{year}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{The Gibbs sampler, the algorithm of Metropolis and similar iterative simulation methods are potentially very helpful for summarizing multivariate distributions. Used naively, however, iterative simulation can give misleading answers. Our methods are simple and generally applicable to the output of any iterative simulation; they are designed for researchers primarily interested in the science underlying the data and models they are analyzing, rather than for researchers interested in the probability theory underlying the iterative simulations themselves. Our recommended strategy is to use several independent sequences, with starting points sampled from an overdispersed distribution. At each step of the iterative simulation, we obtain, for each univariate estimand of interest, a distributional estimate and an estimate of how much sharper the distributional estimate might become if the simulations were contin- ued indefinitely. Because our focus is on applied inference for Bayesian posterior distributions in real problems, which often tend toward normal- ity after transformations and marginalization, we derive our results as normal-theory approximations to exact Bayesian inference, conditional on the observed simulations. The methods are illustrated on a random- effects mixture model applied to experimental measurements of reaction times of normal and schizophrenic patients.}
      \field{issn}{0883-4237}
      \field{journaltitle}{Statistical Science}
      \field{title}{Inference from {Iterative} {Simulation} {Using} {Multiple} {Sequences}}
      \field{year}{1992}
      \verb{doi}
      \verb 10.1214/ss/1177011136
      \endverb
    \endentry
    \entry{geman_stochastic_1984}{article}{}
      \name{author}{2}{}{%
        {{un=1,uniquepart=given,hash=559187c6e8cad5a03e2e2c57be738be0}{%
           family={Geman},
           familyi={G\bibinitperiod},
           given={Stuart},
           giveni={S\bibinitperiod},
           givenun=1}}%
        {{un=1,uniquepart=given,hash=89e4edfb9032a01b35790030deb29681}{%
           family={Geman},
           familyi={G\bibinitperiod},
           given={Donald},
           giveni={D\bibinitperiod},
           givenun=1}}%
      }
      \strng{namehash}{0bb8b7eb2aae2428a08d94af9285141d}
      \strng{fullhash}{0bb8b7eb2aae2428a08d94af9285141d}
      \strng{bibnamehash}{0bb8b7eb2aae2428a08d94af9285141d}
      \strng{authorbibnamehash}{0bb8b7eb2aae2428a08d94af9285141d}
      \strng{authornamehash}{0bb8b7eb2aae2428a08d94af9285141d}
      \strng{authorfullhash}{0bb8b7eb2aae2428a08d94af9285141d}
      \field{sortinit}{G}
      \field{sortinithash}{32d67eca0634bf53703493fb1090a2e8}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{year}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{We make an analogy between images and statistical mechanics systems. Pixel gray levels and the presence and orientation of edges are viewed as states of atoms or molecules in a lattice-like physical system. The assignment of an energy function in the physical system determines its Gibbs distribution. Because of the Gibbs distribution, Markov random field (MRF) equivalence, this assignment also determines an MRF image model. The energy function is a more convenient and natural mechanism for embodying picture attributes than are the local characteristics of the MRF. For a range of degradation mechanisms, including blurring, nonlinear deformations, and multiplicative or additive noise, the posterior distribution is an MRF with a structure akin to the image model. By the analogy, the posterior distribution defines another (imaginary) physical system. Gradual temperature reduction in the physical system isolates low energy states (``annealing''), or what is the same thing, the most probable states under the Gibbs distribution. The analogous operation under the posterior distribution yields the maximum a posteriori (MAP) estimate of the image given the degraded observations. The result is a highly parallel ``relaxation'' algorithm for MAP estimation. We establish convergence properties of the algorithm and we experiment with some simple pictures, for which good restorations are obtained at low signal-to-noise ratios.}
      \field{issn}{01628828}
      \field{journaltitle}{IEEE Transactions on Pattern Analysis and Machine Intelligence}
      \field{month}{6}
      \field{number}{6}
      \field{title}{Stochastic {Relaxation}, {Gibbs} {Distributions}, and the {Bayesian} {Restoration} of {Images}}
      \field{urlday}{21}
      \field{urlmonth}{11}
      \field{urlyear}{2016}
      \field{volume}{PAMI-6}
      \field{year}{1984}
      \field{urldateera}{ce}
      \field{pages}{721\bibrangedash 741}
      \range{pages}{21}
      \verb{doi}
      \verb 10.1109/TPAMI.1984.4767596
      \endverb
      \verb{urlraw}
      \verb http://www.ncbi.nlm.nih.gov/pubmed/22499653
      \endverb
      \verb{url}
      \verb http://www.ncbi.nlm.nih.gov/pubmed/22499653
      \endverb
      \keyw{Annealing,Gibbs distribution,image restoration,line process,MAP estimate,Markov random field,relaxation scene modeling,spatial degradation}
    \endentry
    \entry{hastings_monte_1970}{article}{}
      \name{author}{1}{}{%
        {{un=0,uniquepart=base,hash=e2bb38a445fd9f0c2309f57ade222b9b}{%
           family={Hastings},
           familyi={H\bibinitperiod},
           given={W\bibnamedelima K},
           giveni={W\bibinitperiod\bibinitdelim K\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{e2bb38a445fd9f0c2309f57ade222b9b}
      \strng{fullhash}{e2bb38a445fd9f0c2309f57ade222b9b}
      \strng{bibnamehash}{e2bb38a445fd9f0c2309f57ade222b9b}
      \strng{authorbibnamehash}{e2bb38a445fd9f0c2309f57ade222b9b}
      \strng{authornamehash}{e2bb38a445fd9f0c2309f57ade222b9b}
      \strng{authorfullhash}{e2bb38a445fd9f0c2309f57ade222b9b}
      \field{sortinit}{H}
      \field{sortinithash}{23a3aa7c24e56cfa16945d55545109b5}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{year}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{A generalization of the sampling method introduced by Metropolis et al. (1953) is presented along with an exposition of the relevant theory, techniques of application and methods and difficulties of assessing the error in Monte Carlo estimates. Examples of the methods, including the generation of random orthogonal matrices and potential applications of the methods to numerical problems arising in statistics, are discussed.}
      \field{issn}{00063444}
      \field{journaltitle}{Biometrika}
      \field{number}{1}
      \field{title}{Monte {Carlo} {Sampling} {Methods} {Using} {Markov} {Chains} and {Their} {Applications}}
      \field{volume}{57}
      \field{year}{1970}
      \field{pages}{97\bibrangedash 109}
      \range{pages}{13}
      \verb{urlraw}
      \verb http://www.jstor.org/stable/2334940
      \endverb
      \verb{url}
      \verb http://www.jstor.org/stable/2334940
      \endverb
      \keyw{and edward,arianna w,ation of state calculations,augusta h,by fast computing machines,marshall n,nicholas metropolis,rosenbluth,teller}
    \endentry
    \entry{johnson_using_2003}{article}{}
      \name{author}{2}{}{%
        {{un=0,uniquepart=base,hash=a4c5e53a38f473e3ac06bdc8d5a53006}{%
           family={Johnson},
           familyi={J\bibinitperiod},
           given={Matthew\bibnamedelima S},
           giveni={M\bibinitperiod\bibinitdelim S\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=d4bf1b10b5d0f9db7c2d0e035eb38e6e}{%
           family={Junker},
           familyi={J\bibinitperiod},
           given={Brian\bibnamedelima W},
           giveni={B\bibinitperiod\bibinitdelim W\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{4d0a701ff03a7a2c57fb73a054d6a83e}
      \strng{fullhash}{4d0a701ff03a7a2c57fb73a054d6a83e}
      \strng{bibnamehash}{4d0a701ff03a7a2c57fb73a054d6a83e}
      \strng{authorbibnamehash}{4d0a701ff03a7a2c57fb73a054d6a83e}
      \strng{authornamehash}{4d0a701ff03a7a2c57fb73a054d6a83e}
      \strng{authorfullhash}{4d0a701ff03a7a2c57fb73a054d6a83e}
      \field{sortinit}{J}
      \field{sortinithash}{b2f54a9081ace9966a7cb9413811edb4}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{year}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Unfolding response models, a class of item response theory (IRT) models that assume a unimodal item response function (IRF), are often used for the measurement of attitudes. Verhelst and Verstralen (1993)and Andrich and Luo (1993) independently developed unfolding response models by relating the observed responses to a more common monotone IRT model using a latent response model (LRM; Maris, 1995). This article generalizes their approach, and suggests a data augmentation scheme for the estimation of any unfolding response model. The article introduces two Markov chain Monte Carlo (MCMC) estimation procedures for the Bayesian estimation of unfolding model parameters; one is a direct implementation of MCMC, and the second utilizes the data augmentation method. We use the estimation procedure to analyze three data sets, one simulated, and two from real attitudinal surveys.}
      \field{issn}{1076-9986}
      \field{journaltitle}{Journal of Educational and Behavioral Statistics}
      \field{number}{3}
      \field{title}{Using {Data} {Augmentation} and {Markov} {Chain} {Monte} {Carlo} for the {Estimation} of {Unfolding} {Response} {Models}}
      \field{urlday}{29}
      \field{urlmonth}{6}
      \field{urlyear}{2016}
      \field{volume}{28}
      \field{year}{2003}
      \field{urldateera}{ce}
      \field{pages}{195\bibrangedash 230}
      \range{pages}{36}
      \verb{doi}
      \verb 10.3102/10769986028003195
      \endverb
      \verb{file}
      \verb PDF:/home/xiang/Zotero/storage/5KZDJEDG/Johnson, Junker - 2003 - Using Data Augmentation and Markov Chain Monte Carlo for the Estimation of Unfolding Response Models.pdf:application/pdf;PDF:/home/xiang/Zotero/storage/GFWUL5H2/Johnson, Junker - 2003 - Using Data Augmentation and Markov Chain Monte Carlo for the Estimation of Unfolding Response Models(2).pdf:application/pdf
      \endverb
      \keyw{data augmentation,latent response model,markov chain monte carlo,unfolding}
    \endentry
    \entry{levy_rise_2009}{article}{}
      \name{author}{1}{}{%
        {{un=0,uniquepart=base,hash=7762af597023209d02c37b7cc9ed04dc}{%
           family={Levy},
           familyi={L\bibinitperiod},
           given={Roy},
           giveni={R\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{7762af597023209d02c37b7cc9ed04dc}
      \strng{fullhash}{7762af597023209d02c37b7cc9ed04dc}
      \strng{bibnamehash}{7762af597023209d02c37b7cc9ed04dc}
      \strng{authorbibnamehash}{7762af597023209d02c37b7cc9ed04dc}
      \strng{authornamehash}{7762af597023209d02c37b7cc9ed04dc}
      \strng{authorfullhash}{7762af597023209d02c37b7cc9ed04dc}
      \field{sortinit}{L}
      \field{sortinithash}{7c47d417cecb1f4bd38d1825c427a61a}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{year}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Markov chain Monte Carlo (MCMC) estimation strategies represent a powerful approach to estimation in psychometric models. Popular MCMC samplers and their alignment with Bayesian approaches to modeling are discussed. Key historical and current developments of MCMC are surveyed, emphasizing how MCMC allows the researcher to overcome the limitations of other estimation paradigms, facilitates the estimation of models that might otherwise be intractable, and frees the researcher from certain possible misconceptions about the models.}
      \field{issn}{1687-952X}
      \field{journaltitle}{Journal of Probability and Statistics}
      \field{title}{The {Rise} of {Markov} {Chain} {Monte} {Carlo} {Estimation} for {Psychometric} {Modeling}}
      \field{urlday}{1}
      \field{urlmonth}{8}
      \field{urlyear}{2016}
      \field{volume}{2009}
      \field{year}{2009}
      \field{urldateera}{ce}
      \field{pages}{1\bibrangedash 18}
      \range{pages}{18}
      \verb{doi}
      \verb 10.1155/2009/537139
      \endverb
      \verb{file}
      \verb PDF:/home/xiang/Zotero/storage/QDI8ULLH/Levy - 2009 - The Rise of Markov Chain Monte Carlo Estimation for Psychometric Modeling.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb http://www.hindawi.com/journals/jps/2009/537139/
      \endverb
      \verb{url}
      \verb http://www.hindawi.com/journals/jps/2009/537139/
      \endverb
    \endentry
    \entry{liu_three_2019}{thesis}{}
      \name{author}{1}{}{%
        {{un=0,uniquepart=base,hash=4622823528906a7f86a323f6f41fd33e}{%
           family={Liu},
           familyi={L\bibinitperiod},
           given={Xiang},
           giveni={X\bibinitperiod},
           givenun=0}}%
      }
      \list{institution}{1}{%
        {Columbia University}%
      }
      \strng{namehash}{4622823528906a7f86a323f6f41fd33e}
      \strng{fullhash}{4622823528906a7f86a323f6f41fd33e}
      \strng{bibnamehash}{4622823528906a7f86a323f6f41fd33e}
      \strng{authorbibnamehash}{4622823528906a7f86a323f6f41fd33e}
      \strng{authornamehash}{4622823528906a7f86a323f6f41fd33e}
      \strng{authorfullhash}{4622823528906a7f86a323f6f41fd33e}
      \field{sortinit}{L}
      \field{sortinithash}{7c47d417cecb1f4bd38d1825c427a61a}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{year}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{title}{Three {Contributions} to {Latent} {Variable} {Modeling}}
      \field{type}{Doctoral {Dissertation}}
      \field{year}{2019}
    \endentry
    \entry{liu_estimating_2019}{inbook}{}
      \name{author}{2}{}{%
        {{un=0,uniquepart=base,hash=4622823528906a7f86a323f6f41fd33e}{%
           family={Liu},
           familyi={L\bibinitperiod},
           given={Xiang},
           giveni={X\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=a4c5e53a38f473e3ac06bdc8d5a53006}{%
           family={Johnson},
           familyi={J\bibinitperiod},
           given={Matthew\bibnamedelima S.},
           giveni={M\bibinitperiod\bibinitdelim S\bibinitperiod},
           givenun=0}}%
      }
      \name{editor}{2}{}{%
        {{hash=efb89e0f0a80dde3910e905889b9d062}{%
           family={Davier},
           familyi={D\bibinitperiod},
           given={Matthias},
           giveni={M\bibinitperiod},
           prefix={von},
           prefixi={v\bibinitperiod}}}%
        {{hash=d4ac37b59d0b786065dddcc860802c67}{%
           family={Lee},
           familyi={L\bibinitperiod},
           given={Young-Sun},
           giveni={Y\bibinithyphendelim S\bibinitperiod}}}%
      }
      \list{publisher}{1}{%
        {Springer}%
      }
      \strng{namehash}{e69ab651ac624c65368244b47641e41d}
      \strng{fullhash}{e69ab651ac624c65368244b47641e41d}
      \strng{bibnamehash}{e69ab651ac624c65368244b47641e41d}
      \strng{authorbibnamehash}{e69ab651ac624c65368244b47641e41d}
      \strng{authornamehash}{e69ab651ac624c65368244b47641e41d}
      \strng{authorfullhash}{e69ab651ac624c65368244b47641e41d}
      \strng{editorbibnamehash}{f407915222a5c02a67af992132e4866b}
      \strng{editornamehash}{f407915222a5c02a67af992132e4866b}
      \strng{editorfullhash}{f407915222a5c02a67af992132e4866b}
      \field{sortinit}{L}
      \field{sortinithash}{7c47d417cecb1f4bd38d1825c427a61a}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{year}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{booktitle}{Handbook of {Diagnostic} {Classification} {Models}}
      \field{title}{Estimating {CDMs} {Using} {MCMC}}
      \field{year}{2019}
      \field{pages}{629\bibrangedash 646}
      \range{pages}{18}
    \endentry
    \entry{maris_gibbs_2015}{article}{}
      \name{author}{3}{}{%
        {{un=0,uniquepart=base,hash=f8a574289ebf29d1562d768676a90a38}{%
           family={Maris},
           familyi={M\bibinitperiod},
           given={Gunter},
           giveni={G\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=2adf6ac687329792d5497638d9548dc4}{%
           family={Bechger},
           familyi={B\bibinitperiod},
           given={Timo},
           giveni={T\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=cddec31715ec720918603d369fbf206f}{%
           family={San\bibnamedelima Martin},
           familyi={S\bibinitperiod\bibinitdelim M\bibinitperiod},
           given={Ernesto},
           giveni={E\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{a94a692a417d2b368e000fff95ae588b}
      \strng{fullhash}{51db60f14efc8b86fbd6e8a5dd3729ad}
      \strng{bibnamehash}{51db60f14efc8b86fbd6e8a5dd3729ad}
      \strng{authorbibnamehash}{51db60f14efc8b86fbd6e8a5dd3729ad}
      \strng{authornamehash}{a94a692a417d2b368e000fff95ae588b}
      \strng{authorfullhash}{51db60f14efc8b86fbd6e8a5dd3729ad}
      \field{sortinit}{M}
      \field{sortinithash}{4625c616857f13d17ce56f7d4f97d451}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{year}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{In their seminal work on characterizing the manifest probabilities of latent trait models, Cressie and Holland give a theoretically important characterization of the marginal Rasch model. Because their representation of the marginal Rasch model does not involve any latent trait, nor any specific distribution of a latent trait, it opens up the possibility for constructing a Markov chain - Monte Carlo method for Bayesian inference for the marginal Rasch model that does not rely on data augmentation. Such an approach would be highly efficient as its computational cost does not depend on the number of respondents, which makes it suitable for large-scale educational measurement. In this paper, such an approach will be developed and its operating characteristics illustrated with simulated data.}
      \field{issn}{1860-0980}
      \field{journaltitle}{Psychometrika}
      \field{month}{12}
      \field{number}{4}
      \field{title}{A {Gibbs} {Sampler} for the ({Extended}) {Marginal} {Rasch} {Model}.}
      \field{urlday}{20}
      \field{urlmonth}{4}
      \field{urlyear}{2017}
      \field{volume}{80}
      \field{year}{2015}
      \field{urldateera}{ce}
      \field{pages}{859\bibrangedash 79}
      \range{pages}{21}
      \verb{doi}
      \verb 10.1007/s11336-015-9479-4
      \endverb
      \verb{file}
      \verb PDF:/home/xiang/Zotero/storage/N47B9A29/Maris, Bechger, San Martin - 2015 - A Gibbs Sampler for the (Extended) Marginal Rasch Model.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb http://www.ncbi.nlm.nih.gov/pubmed/26493183
      \endverb
      \verb{url}
      \verb http://www.ncbi.nlm.nih.gov/pubmed/26493183
      \endverb
    \endentry
    \entry{neal_probabilistic_1998}{article}{}
      \name{author}{1}{}{%
        {{un=0,uniquepart=base,hash=f366a77ba01bf711161e56bcc244e7f2}{%
           family={Neal},
           familyi={N\bibinitperiod},
           given={Radford\bibnamedelima M},
           giveni={R\bibinitperiod\bibinitdelim M\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{f366a77ba01bf711161e56bcc244e7f2}
      \strng{fullhash}{f366a77ba01bf711161e56bcc244e7f2}
      \strng{bibnamehash}{f366a77ba01bf711161e56bcc244e7f2}
      \strng{authorbibnamehash}{f366a77ba01bf711161e56bcc244e7f2}
      \strng{authornamehash}{f366a77ba01bf711161e56bcc244e7f2}
      \strng{authorfullhash}{f366a77ba01bf711161e56bcc244e7f2}
      \field{sortinit}{N}
      \field{sortinithash}{22369a73d5f88983a108b63f07f37084}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{year}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Probabilistic inference is an attractive approach to uncertain reasoning and empirical learning in artificial intelligence. Computational difficulties arise, however, because probabilistic models with the necessary realism and flexibility lead to complex distributions over high-dimensional spaces. Related problems in other fields have been tackled using Monte Carlo methods based on sampling using Markov chains, providing a rich array of techniques that can be applied to problems in artificial intelligence. The "Metropolis algorithm" has been used to solve difficult problems in statistical physics for over forty years, and, in the last few years, the related method of "Gibbs sampling" has been applied to the problems of statistical inference. Concurrently, an alternative method for solving problems in statistical physics by means of dynamical simulations has been developed as well, and has recently been unified with the Metropolis algorithm to produce the "hybrid Monte Carlo" method. In computer science, Markov chain sampling is the basis of the heuristic optimization technique of "simulated annealing", and has recently been used in randomized algorithms for approximate counting of large sets. In this review, I outline the role of probabilistic inference in artificial intelligence, present the theory of Markov chains, and describe various Markov chain Monte Carlo algorithms, along with a number of supporting techniques. I try to present a comprehensive picture of the range of methods that have been developed, including techniques from the varied literature that have not yet seen wide application in artificial intelligence, but which appear relevant. As illustrative examples, I use the problems of probabilistic inference in expert systems, discovery of latent classes from data, and Bayesian learning for neural networks.}
      \field{issn}{15206025}
      \field{journaltitle}{Technical Report}
      \field{title}{Probabilistic {Inference} {Using} {Markov} {Chain} {Monte} {Carlo} {Methods}}
      \field{volume}{1}
      \field{year}{1998}
      \field{pages}{1\bibrangedash 144}
      \range{pages}{144}
      \verb{doi}
      \verb 10.1021/np100920q
      \endverb
      \verb{urlraw}
      \verb papers2://publication/uuid/0C88167E-5379-4E4E-A9E4-007ABA4F716D
      \endverb
      \verb{url}
      \verb papers2://publication/uuid/0C88167E-5379-4E4E-A9E4-007ABA4F716D
      \endverb
    \endentry
    \entry{ozturk_bayesian_2017}{article}{}
      \name{author}{2}{}{%
        {{un=0,uniquepart=base,hash=40d4f114b12ffb9a3d81c162e1c6a8aa}{%
           family={Öztürk},
           familyi={Ö\bibinitperiod},
           given={Nicole\bibnamedelima K.},
           giveni={N\bibinitperiod\bibinitdelim K\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=d87eefad279190f0f8d75c4ad23a3dbc}{%
           family={Karabatsos},
           familyi={K\bibinitperiod},
           given={George},
           giveni={G\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{9ac8e75ee9a0a4b6df788d14dd74f0ca}
      \strng{fullhash}{9ac8e75ee9a0a4b6df788d14dd74f0ca}
      \strng{bibnamehash}{9ac8e75ee9a0a4b6df788d14dd74f0ca}
      \strng{authorbibnamehash}{9ac8e75ee9a0a4b6df788d14dd74f0ca}
      \strng{authornamehash}{9ac8e75ee9a0a4b6df788d14dd74f0ca}
      \strng{authorfullhash}{9ac8e75ee9a0a4b6df788d14dd74f0ca}
      \field{sortinit}{Ö}
      \field{sortinithash}{2cd7140a07aea5341f9e2771efe90aae}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{year}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{In psychometric practice, the parameter estimates of a standard item-response theory (IRT) model can become biased when item-response data, of persons’ individual responses to test items, contain outliers relative to the model. Also, the manual removal of outliers can be a time-consuming and difficult task. Besides, removing outliers leads to data information loss in parameter estimation. To address these concerns, a Bayesian IRT model that includes person and latent item-response outlier parameters, in addition to person ability and item parameters, is proposed and illustrated, and is defined by item characteristic curves (ICCs) that are each specified by a robust, Student’s t-distribution function. The outlier parameters and the robust ICCs enable the model to automatically identify item-response outliers, and to make estimates of the person ability and item parameters more robust to outliers. Hence, under this IRT model, it is unnecessary to remove outliers from the data analysis. Our IRT model is illu...}
      \field{issn}{15523497}
      \field{journaltitle}{Applied Psychological Measurement}
      \field{month}{5}
      \field{number}{3}
      \field{title}{A {Bayesian} {Robust} {IRT} {Outlier}-{Detection} {Model}}
      \field{urlday}{20}
      \field{urlmonth}{6}
      \field{urlyear}{2018}
      \field{volume}{41}
      \field{year}{2017}
      \field{urldateera}{ce}
      \field{pages}{195\bibrangedash 208}
      \range{pages}{14}
      \verb{doi}
      \verb 10.1177/0146621616679394
      \endverb
      \verb{file}
      \verb PDF:/home/xiang/Zotero/storage/288UJJU3/0146621616679394.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb http://journals.sagepub.com/doi/10.1177/0146621616679394
      \endverb
      \verb{url}
      \verb http://journals.sagepub.com/doi/10.1177/0146621616679394
      \endverb
      \keyw{dichotomous items,item-response theory,misfit,polytomous items}
    \endentry
    \entry{rizopoulos_ltm_2015}{article}{}
      \name{author}{1}{}{%
        {{un=0,uniquepart=base,hash=68f951c5caa662e5b3cf20be18f5acef}{%
           family={Rizopoulos},
           familyi={R\bibinitperiod},
           given={Dimitris},
           giveni={D\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{68f951c5caa662e5b3cf20be18f5acef}
      \strng{fullhash}{68f951c5caa662e5b3cf20be18f5acef}
      \strng{bibnamehash}{68f951c5caa662e5b3cf20be18f5acef}
      \strng{authorbibnamehash}{68f951c5caa662e5b3cf20be18f5acef}
      \strng{authornamehash}{68f951c5caa662e5b3cf20be18f5acef}
      \strng{authorfullhash}{68f951c5caa662e5b3cf20be18f5acef}
      \field{sortinit}{R}
      \field{sortinithash}{5e1c39a9d46ffb6bebd8f801023a9486}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{year}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{The R package ltm has been developed for the analysis of multivariate dichotomous and polytomous data using latent variable models, under the Item Response Theory approach. For dichotomous data the Rasch, the Two-Parameter Logistic, and Birnbaum’s Three-Parameter models have been implemented, whereas for polytomous data Semejima’s Graded Response model is available. Parameter estimates are obtained under marginal maximum likelihood using the Gauss-Hermite quadrature rule. The capabilities and features of the package are illustrated using two real data examples}
      \field{issn}{1548-7660}
      \field{journaltitle}{Journal of Statistical Software}
      \field{month}{11}
      \field{number}{5}
      \field{title}{ltm : {An} {R} {Package} for {Latent} {Variable} {Modeling} and {Item} {Response} {Theory} {Analyses}}
      \field{urlday}{28}
      \field{urlmonth}{5}
      \field{urlyear}{2019}
      \field{volume}{17}
      \field{year}{2015}
      \field{urldateera}{ce}
      \field{pages}{1\bibrangedash 25}
      \range{pages}{25}
      \verb{doi}
      \verb 10.18637/jss.v017.i05
      \endverb
      \verb{urlraw}
      \verb http://www.jstatsoft.org/v17/i05/
      \endverb
      \verb{url}
      \verb http://www.jstatsoft.org/v17/i05/
      \endverb
    \endentry
    \entry{rubin_bayesianly_1984}{article}{}
      \name{author}{1}{}{%
        {{un=0,uniquepart=base,hash=49a367b6280de8a239f8bbdd573f996f}{%
           family={Rubin},
           familyi={R\bibinitperiod},
           given={Donald\bibnamedelima B.},
           giveni={D\bibinitperiod\bibinitdelim B\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{49a367b6280de8a239f8bbdd573f996f}
      \strng{fullhash}{49a367b6280de8a239f8bbdd573f996f}
      \strng{bibnamehash}{49a367b6280de8a239f8bbdd573f996f}
      \strng{authorbibnamehash}{49a367b6280de8a239f8bbdd573f996f}
      \strng{authornamehash}{49a367b6280de8a239f8bbdd573f996f}
      \strng{authorfullhash}{49a367b6280de8a239f8bbdd573f996f}
      \field{sortinit}{R}
      \field{sortinithash}{5e1c39a9d46ffb6bebd8f801023a9486}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{year}
      \true{uniqueprimaryauthor}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{A common reaction among applied statisticians is that the Bayesian statistician's energies in an applied problem must be directed at the a priori elicitation of one model specification from which an optimal design and all inferences follow automatically by applying Bayes's theorem to calculate conditional distributions of unknowns given knowns. I feel, however, that the applied Bayesian statistician's tool-kit should be more extensive and include tools that may be usefully labeled frequency calculations. Three types of Bayesianly justifiable and relevant frequency calculations are presented using examples to convey their use for the applied statistician.}
      \field{issn}{0090-5364}
      \field{journaltitle}{The Annals of Statistics}
      \field{number}{4}
      \field{title}{Bayesianly {Justifiable} and {Relevant} {Frequency} {Calculations} for the {Applied} {Statistician}}
      \field{volume}{12}
      \field{year}{1984}
      \field{pages}{1151\bibrangedash 1172}
      \range{pages}{22}
      \verb{doi}
      \verb 10.1214/aos/1176346785
      \endverb
      \verb{urlraw}
      \verb http://projecteuclid.org/euclid.aos/1176346785
      \endverb
      \verb{url}
      \verb http://projecteuclid.org/euclid.aos/1176346785
      \endverb
    \endentry
    \entry{sinharay_assessment_2015}{article}{}
      \name{author}{1}{}{%
        {{un=0,uniquepart=base,hash=84472f2fcb73631ec1599a478b0326f0}{%
           family={Sinharay},
           familyi={S\bibinitperiod},
           given={S.},
           giveni={S\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{84472f2fcb73631ec1599a478b0326f0}
      \strng{fullhash}{84472f2fcb73631ec1599a478b0326f0}
      \strng{bibnamehash}{84472f2fcb73631ec1599a478b0326f0}
      \strng{authorbibnamehash}{84472f2fcb73631ec1599a478b0326f0}
      \strng{authornamehash}{84472f2fcb73631ec1599a478b0326f0}
      \strng{authorfullhash}{84472f2fcb73631ec1599a478b0326f0}
      \field{extraname}{1}
      \field{sortinit}{S}
      \field{sortinithash}{b164b07b29984b41daf1e85279fbc5ab}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{year}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{Person-fit assessment may help the researcher to obtain additional information regarding the answering behavior of persons. Although several researchers examined person fit, there is a lack of research on person-fit assessment for mixed-format tests. In this article, the lz statistic and the \{zeta\}2 statistic, both of which have been used for tests with only dichotomous items or with only polytomous items, were modified for use with mixed-format tests. In a detailed simulation, the lz and \{zeta\}2 statistics are found to be conservative under a (frequentist) asymptotic normal approximation. However, the use of the statistics along with the (Bayesian) posterior predictive model checking method leads to a larger power. The suggested approaches are applied to an operational data set. The approaches appear to be satisfactory tools for assessing person fit for mixed-format tests.}
      \field{issn}{1076-9986}
      \field{journaltitle}{Journal of Educational and Behavioral Statistics}
      \field{number}{4}
      \field{title}{Assessment of {Person} {Fit} for {Mixed}-{Format} {Tests}}
      \field{volume}{40}
      \field{year}{2015}
      \field{pages}{343\bibrangedash 365}
      \range{pages}{23}
      \verb{doi}
      \verb 10.3102/1076998615589128
      \endverb
      \verb{file}
      \verb PDF:/home/xiang/Zotero/storage/IRQNBBV5/Sinharay - 2016 - Assessment of Person Fit Using Resampling-Based Approaches.pdf:application/pdf
      \endverb
    \endentry
    \entry{sinharay_assessing_2005}{article}{}
      \name{author}{1}{}{%
        {{un=0,uniquepart=base,hash=ffb04874bec5ae131fa94f9f46c35c36}{%
           family={Sinharay},
           familyi={S\bibinitperiod},
           given={Sandip},
           giveni={S\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{ffb04874bec5ae131fa94f9f46c35c36}
      \strng{fullhash}{ffb04874bec5ae131fa94f9f46c35c36}
      \strng{bibnamehash}{ffb04874bec5ae131fa94f9f46c35c36}
      \strng{authorbibnamehash}{ffb04874bec5ae131fa94f9f46c35c36}
      \strng{authornamehash}{ffb04874bec5ae131fa94f9f46c35c36}
      \strng{authorfullhash}{ffb04874bec5ae131fa94f9f46c35c36}
      \field{extraname}{2}
      \field{sortinit}{S}
      \field{sortinithash}{b164b07b29984b41daf1e85279fbc5ab}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{year}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{issn}{0022-0655}
      \field{journaltitle}{Journal of Educational Measurement}
      \field{month}{12}
      \field{number}{4}
      \field{title}{Assessing {Fit} of {Unidimensional} {Item} {Response} {Theory} {Models} {Using} a {Bayesian} {Approach}}
      \field{urlday}{9}
      \field{urlmonth}{10}
      \field{urlyear}{2017}
      \field{volume}{42}
      \field{year}{2005}
      \field{urldateera}{ce}
      \field{pages}{375\bibrangedash 394}
      \range{pages}{20}
      \verb{doi}
      \verb 10.1111/j.1745-3984.2005.00021.x
      \endverb
      \verb{file}
      \verb PDF:/home/xiang/Zotero/storage/LBPTYERQ/Sinharay - 2005 - Assessing Fit of Unidimensional Item Response Theory Models Using a Bayesian Approach.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb http://doi.wiley.com/10.1111/j.1745-3984.2005.00021.x
      \endverb
      \verb{url}
      \verb http://doi.wiley.com/10.1111/j.1745-3984.2005.00021.x
      \endverb
    \endentry
    \entry{sinharay_assessing_2007}{article}{}
      \name{author}{2}{}{%
        {{un=0,uniquepart=base,hash=ffb04874bec5ae131fa94f9f46c35c36}{%
           family={Sinharay},
           familyi={S\bibinitperiod},
           given={Sandip},
           giveni={S\bibinitperiod},
           givenun=0}}%
        {{un=0,uniquepart=base,hash=16b8c10727252183084fa165f2a25f9e}{%
           family={Almond},
           familyi={A\bibinitperiod},
           given={Russell\bibnamedelima G},
           giveni={R\bibinitperiod\bibinitdelim G\bibinitperiod},
           givenun=0}}%
      }
      \strng{namehash}{d4b18f4e0e66eba2a5283d0006305da1}
      \strng{fullhash}{d4b18f4e0e66eba2a5283d0006305da1}
      \strng{bibnamehash}{d4b18f4e0e66eba2a5283d0006305da1}
      \strng{authorbibnamehash}{d4b18f4e0e66eba2a5283d0006305da1}
      \strng{authornamehash}{d4b18f4e0e66eba2a5283d0006305da1}
      \strng{authorfullhash}{d4b18f4e0e66eba2a5283d0006305da1}
      \field{sortinit}{S}
      \field{sortinithash}{b164b07b29984b41daf1e85279fbc5ab}
      \field{extradatescope}{labelyear}
      \field{labeldatesource}{year}
      \field{labelnamesource}{author}
      \field{labeltitlesource}{title}
      \field{abstract}{A cognitive diagnostic model uses information from educational experts to describe the relationships between item performances and posited proficiencies. When the cognitive relationships can be described using a fully Bayesian model, Bayesian model checking procedures become available. Checking models tied to cognitive theory of the domains provides feedback to educators about the underlying cognitive theory. This article suggests a number of graphics and statistics for diagnosing problems with cognitive diagnostic models expressed as Bayesian networks. The suggested diagnostics allow the authors to identify the inadequacy of an earlier cognitive diagnostic model and to hypothesize an improved model that provides better fit to the data. (Contains 4 figures and 3 tables.)}
      \field{issn}{0013-1644}
      \field{journaltitle}{Educational and Psychological Measurement}
      \field{number}{2}
      \field{title}{Assessing {Fit} of {Cognitive} {Diagnostic} {Models} {A} {Case} {Study}}
      \field{urlday}{6}
      \field{urlmonth}{10}
      \field{urlyear}{2017}
      \field{volume}{67}
      \field{year}{2007}
      \field{urldateera}{ce}
      \field{pages}{239\bibrangedash 257}
      \range{pages}{19}
      \verb{doi}
      \verb 10.1177/0013164406292025
      \endverb
      \verb{file}
      \verb PDF:/home/xiang/Zotero/storage/MBFYVY34/Sinharay, Almond - 2007 - Assessing Fit of Cognitive Diagnostic Models A Case Study.pdf:application/pdf
      \endverb
      \verb{urlraw}
      \verb http://journals.sagepub.com/doi/10.1177/0013164406292025
      \endverb
      \verb{url}
      \verb http://journals.sagepub.com/doi/10.1177/0013164406292025
      \endverb
      \keyw{Bayesian network,Bayesian residual,DIC,item fit,Markov chain Monte Carlo}
    \endentry
  \enddatalist
\endrefsection
\endinput

